在电商、支付等系统中，一般都是先创建订单（支付单），再给用户一定的时间进行支付，如果没有按时支付的话，就需要把之前的订单（支付单）取消掉。这种类似的场景有很多，还有比如到期自动收货、超时自动退款、下单后自动发送短信等等都是类似的业务问题。 

##订单的到期关闭的实现有很多种方式，分别有：

1. 被动关闭（不推荐） 
2. 定时任务（**推荐**，适合时间精确度要求不高的场景） 
3. DelayQueue（不推荐，基于内存，无法持久化） 
4. 时间轮（不推荐，基于内存，无法持久化） 
5. kafka（MQ 方案不推荐，大量无效调度） 
6. RocketMQ延迟消息（MQ 方案不推荐，大量无效调度） 
7. RabbitMQ死信队列（MQ 方案不推荐，大量无效调度） 
8. RabbitMQ插件（MQ 方案不推荐，大量无效调度） 
9. Redis过期监听（不推荐，容易丢消息） 
10. Redis的ZSet（不推荐，可能会重复消费） 
11. Redisson（**推荐**，可以用） 

### 实现的复杂度上（包含用到的框架的依赖及部署）： 

Redisson > RabbitMQ插件 > RabbitMQ死信队列 > RocketMQ延迟消息 ≈ Redis的zset > Redis过期监听 ≈ kafka时间轮 > 定时任务 > Netty的时间轮 > JDK自带的DelayQueue > 被动关闭 

### 不同的场景中也适合不同的方案： 

- 自己玩玩：被动关闭  
- 单体应用，业务量不大：Netty的时间轮、JDK自带的DelayQueue、定时任务  
- 分布式应用，业务量不大：Redis过期监听、RabbitMQ死信队列、Redis的zset、定时任务  
- 分布式应用，业务量大、并发高：Redisson、RabbitMQ插件、kafka时间轮、RocketMQ延迟消息、定时任务  
- 业务量特别大：定时任务

总体考虑的话，考虑到成本，方案完整性、以及方案的复杂度，还有用到的第三方框架的流行度来说，个人比较建议优先考虑定时任务、Redisson+Redis、RabbitMQ插件、RocketMQ延迟消息等方案。 

**但是，如果考虑到订单到期关闭的业务特点，如果在订单量特别大的时候，MQ其实并不适合【尤其是可靠性和无效消息】：** 

[为什么不建议使用MQ实现订单到期关闭？ ](为什么不建议使用MQ实现订单到期关闭.md)

##【拓展知识】

### 一、被动关闭 

在解决这类问题的时候，有一种比较简单的方式，那就是通过业务上的被动方式来进行关单操作。  

简单点说，就是订单创建好了之后。我们系统上不做主动关单，**什么时候用户来访问这个订单了，再去判断时间是不是超过了过期时间**，如果过了时间那就进行关单操作，然后再提示用户。   

这种做法是最简单的，基本不需要开发定时关闭的功能，但是他的缺点也很明显，那就是如果用户**一直不来查看这个订单**，那么就会有很多脏数据冗余在数据库中一直无法被关单。  

还有一个缺点，那就是需要在用户的查询过程中进行写的操作，一般写操作都会比读操作耗时更长，而且有失败的可能，一旦关单失败了，就会导致系统处理起来比较复杂。  

所以，这种方案只适合于自己学习的时候用，**任何商业网站中都不建议使用这种方案来实现订单关闭的功能。**   

### 二、定时任务 

定时任务关闭订单，这是很容易想到的一种方案。  

具体实现细节就是我们通过一些调度平台来实现定时执行任务，任务就是去扫描所有到期的订单，然后执行关单动作。  

这个方案的优点也是比较简单，实现起来很**容易**，基于Timer、ScheduledThreadPoolExecutor、或者像xxl-job这类调度框架都能实现，但是有以下几个问题：  

1. **时间不精准。** 一般定时任务基于固定的频率、按照时间定时执行的，那么就可能会发生很多订单已经到了超时时间，但是定时任务的调度时间还没到，那么就会导致这些订单的实际关闭时间要比应该关闭的时间晚一些。  
2. **无法处理大订单量。** 定时任务的方式是会把本来比较分散的关闭时间集中到任务调度的那一段时间，如果订单量比较大的话，那么就可能导致任务执行时间很长，整个任务的时间越长，订单被扫描到时间可能就很晚，那么就会导致关闭时间更晚。  
3. **对数据库造成压力。** 定时任务集中扫表，这会使得数据库IO在短时间内被大量占用和消耗，如果没有做好隔离，并且业务量比较大的话，就可能会影响到线上的正常业务。  
4. **分库分表问题。** 订单系统，一旦订单量大就可能会考虑分库分表，在分库分表中进行全表扫描，这是一个极不推荐的方案。   

这些问题的解决方案如下： 

[定时任务扫表的方案有什么缺点?](定时任务扫表的方案有什么缺点.md)

### 三、JDK自带的DelayQueue

有这样一种方案，他不需要借助任何外部的资源，直接基于应用自身就能实现，那就是基于JDK自带的DelayQueue来实现。 

> DelayQueue是一个无界的BlockingQueue，用于放置实现了Delayed接口的对象，其中的对象只能在其到期时才能从队列中取走。 

基于延迟队列，是可以实现订单的延迟关闭的，首先，在用户创建订单的时候，把订单加入到DelayQueue中，然后，还需要一个常驻任务不断的从队列中取出那些到了超时时间的订单，然后在把他们进行关单，之后再从队列中删除掉。  

这个方案需要有一个线程，不断的从队列中取出需要关单的订单。一般在这个线程中需要加一个while(true)循环，这样才能确保任务不断的执行并且能够及时的取出超时订单。  

使用DelayQueue实现超时关单的方案，**实现起来简单**，不须要依赖第三方的框架和类库，JDK原生就支持了。  

当然这个方案也不是没有缺点的，首先，基于DelayQueue的话，需要把订单放进去，**那如果订单量太大的话**，**可能会导致OOM的问题**；另外，**DelayQueue是基于JVM内存的，一旦机器重启了，里面的数据就都没有了**。虽然我们可以配合数据库的持久化一起使用。而且现在很多应用都是集群部署的，那么**集群中多个实例上的多个DelayQueue如何配合是一个很大的问题。**  

所以，**基于JDK的DelayQueue方案只适合在单机场景、并且数据量不大的场景中使用，如果涉及到分布式场景，那还是不建议使用。** 

### 四、Netty的时间轮

还有一种方式，和上面我们提到的JDK自带的DelayQueue类似的方式，那就是**基于时间轮**实现。  

为什么要有时间轮呢？主要是因为DelayQueue插入和删除操作的平均时间复杂度——**O(nlog(n))**，虽然已经挺好的了，但是时间轮的方案可以将插入和删除操作的时间复杂度都降为**O(1)**。 

基于Netty的`HashedWheelTimer`可以帮助我们快速的实现一个时间轮，这种方式和DelayQueue类似，缺点都是**基于内存、集群扩展**麻烦、内存有限制等等。  

但是他相比DelayQueue的话，**效率更高一些，任务触发的延迟更低**。代码实现上面也更加精简。  

所以，基于Netty的时间轮方案比基于JDK的DelayQueue效率更高，实现起来更简单，但是同样的，**只适合在单机场景、并且数据量不大的场景中使用**，如果涉及到分布式场景，那还是不建议使用。 

### 五、Kafka的时间轮 

既然基于Netty的时间轮存在一些问题，那么有没有其他的时间轮的实现呢？  

还真有的，那就是Kafka的时间轮，Kafka内部有很多延时性的操作，如延时生产，延时拉取，延时数据删除等，这些延时功能由内部的延时操作管理器来做专门的处理，其底层是采用时间轮实现的。  

而且，为了解决有一些时间跨度大的延时任务，Kafka 还引入了**层级时间轮**，能更好控制时间粒度，可以应对更加复杂的定时任务处理场景；  Kafka 中的时间轮的实现是 TimingWheel 类，位于 kafka.utils.timer 包中。基于Kafka的时间轮同样可以得到O(1)时间复杂度，性能上还是不错的。  

**基于Kafka的时间轮的实现方式，在实现方式上有点复杂，需要依赖kafka，但是他的稳定性和性能都要更高一些，而且适合用在分布式场景中。**   

> 下面我来详细解释一下 Kafka 和 RocketMQ 在“延迟消息”上的区别，以及 Kafka 的相关延时操作和 RocketMQ 的强大延迟消息功能。
>
> ---
>
> ## Kafka 的延时相关操作
>
> Kafka 设计上是一个高吞吐的分布式消息队列，但它**原生不支持“延迟消息”**（即：消息在指定延迟后才可被消费）。Kafka 内部存在一些“延时性操作”，但它们和延迟消息的概念不同，主要包括：
>
> - **延时生产**：生产者可以选择在某个时间段后才发送消息，但这是生产者的行为，Kafka本身不管理。
> - **延时拉取（消费）**：消费者可以选择什么时候拉取消息，但 Kafka 只负责存储和投递，不控制消息的消费时机。
> - **延时数据删除（Retention）**：Kafka 通过配置保留策略（如消息保留时间、日志文件大小等）来延迟数据的删除，但这和消息的投递无关。
> - 有一些“延迟队列”的实现方案，比如把消息投递到一个特殊Topic，然后由定时任务轮询到期消息，但这不是 Kafka 的原生功能，有性能和实现上的局限。
>
> **总结**：Kafka 的延时性操作主要是生产、消费和数据生命周期的延迟，但**不原生支持延迟消息**。
>
> ---
>
> ## RocketMQ 的强大延迟消息功能
>
> RocketMQ 则**原生支持延迟消息**，这是它的一个重要特性。在 RocketMQ 中：
>
> - 发送消息时可以指定一个“延迟级别”（delayLevel），消息会在指定延迟后才被消费者消费。
> - 延迟级别通常是预先配置好的，比如延迟1s、5s、10s、30s、1min等等（RocketMQ默认支持18个延迟级别）。
> - RocketMQ内部会将延迟消息存储到特殊队列，延迟时间到达后再投递到消费队列。
> - 这对于实现“定时任务”、“订单超时取消”、“延迟业务通知”等场景非常方便且高效。
>
> **RocketMQ的延迟消息优势：**
> - **原生支持**，无需额外开发。
> - 延迟粒度丰富，可精确到秒级。
> - 性能和可靠性高，适合大规模业务场景。
>
> ---
>
> ## 对比总结
>
> - **Kafka**：没有原生延迟消息功能，延迟相关操作只是生产/消费/删除的时间控制，本质上不是“延迟队列”。
> - **RocketMQ**：原生支持延迟消息，方便实现定时/延迟消费场景，是其一大优势。
>
> 如果你的业务场景需要大量的“延迟消息”处理，RocketMQ会更加合适；而Kafka则需额外开发延迟队列方案，复杂度和性能都会受到影响。

### 六、RocketMQ延迟消息 

相比于Kafka来说，RocketMQ中有一个强大的功能，那就是支持延迟消息。 

> 延迟消息，当消息写入到Broker后，不会立刻被消费者消费，需要等待指定的时长后才可被消费处理的消息，称为延时消息。 

有了延迟消息，我们就可以在订单创建好之后，发送一个延迟消息，比如20分钟取消订单，那就发一个延迟20分钟的延迟消息，然后在20分钟之后，消息就会被消费者消费，消费者在接收到消息之后，去关单就行了。  

但是，RocketMQ的延迟消息**并不是支持任意时长的延迟的**，它只支持：1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h这几个时长。（商业版支持任意时长）  

可以看到，有了RocketMQ延迟消息之后，我们处理上就简单很多，只需要发消息，和接收消息就行了，系统之间完全解耦了。**但是因为延迟消息的时长受到了限制，所以并不是很灵活。**  

**如果我们的业务上，关单时长刚好和RocketMQ延迟消息支持的时长匹配的话，那么是可以基于RocketMQ延迟消息来实现的。否则，这种方式并不是最佳的。（但是在RocketMQ 5.0中新增了基于时间轮实现的定时消息，可以解决这个问题！）** 

### 七、RabbitMQ死信队列

延迟消息不仅在RocketMQ中支持，其实在RabbitMQ中也是可以实现的，只不过其底层是基于死信队列实现的。  

当RabbitMQ中的一条正常的消息，因为过了存活时间（TTL过期）、队列长度超限、被消费者拒绝等原因无法被消费时，就会变成Dead Message，即死信。  

**当一个消息变成死信之后，他就能被重新发送到死信队列中（其实是交换机-exchange）。**  

那么基于这样的机制，就可以实现延迟消息了。那就是我们给一个消息设定TTL，但是并不消费这个消息，等他过期，过期后就会进入到死信队列，然后我们再监听死信队列的消息消费就行了。  

而且，RabbitMQ中的这个TTL是**可以设置任意时长的，这就解决了RocketMQ的不灵活的问题。**  

但是，死信队列的实现方式存在一个问题，那就是**可能造成队头阻塞**，如果死信队列中的队头的消息一直无法消费成功，那么就会阻塞整个队列，这时候即使排在他后面的消息过期需要处理了，那么也会被一直阻塞。  

**基于RabbitMQ的死信队列，可以实现延迟消息，非常灵活的实现定时关单，并且借助RabbitMQ的集群扩展性，可以实现高可用，以及处理大并发量。他的缺点第一是可能存在消息阻塞的问题，还有就是方案比较复杂，不仅要依赖RabbitMQ，而且还需要声明很多队列(exchange)出来，增加系统的复杂度。** 

### 八、RabbitMQ插件 

其实，基于RabbitMQ的话，可以不用死信队列也能实现延迟消息，那就是基于`rabbitmq_delayed_message_exchange`插件，这种方案能够解决通过死信队列实现延迟消息出现的消息阻塞问题。但是该插件从RabbitMQ的3.6.12开始支持的，所以对版本有要求。  

这个插件是官方出的，可以放心使用，安装并启用这个插件之后，就可以创建x-delayed-message类型的队列了。  

前面我们提到的基于死信队列的方式，是消息先会投递到一个正常队列，在TTL过期后进入死信队列。但是基于插件的这种方式，消息并不会立即进入队列，而是先把他们保存在一个基于Erlang开发的Mnesia数据库中，然后通过一个定时器去查询需要被投递的消息，再把他们投递到x-delayed-message队列中。  

**基于RabbitMQ插件的方式可以实现延迟消息，并且不存在消息阻塞的问题，但是因为是基于插件的，而这个插件支持的最大延长时间是(2^32)-1 毫秒，大约49天，超过这个时间就会被立即消费。但是他基于RabbitMQ实现，所以在可用性、性能方便都很不错** 

### 九、Redis过期监听 

很多用过Redis的人都知道，Redis有一个**过期监听的功能**，  

在 redis.conf 中，加入一条配置`notify-keyspace-events Ex`开启过期监听，然后再代码中实现一个KeyExpirationEventMessageListener，就可以监听key的过期消息了。  

这样就可以在接收到过期消息的时候，进行订单的关单操作。 

这个方案**不建议**大家使用，是因为Redis官网上明确的说过，**Redis并不保证Key在过期的时候就能被立即删除**，**更不保证这个消息能被立即发出**。所以，消息延迟是必然存在的，随着数据量越大延迟越长，延迟个几分钟都是常事儿。  

而且，在Redis 5.0之前，这个消息是通过PUB/SUB模式发出的，他**不会做持久化**，至于你有没有接到，有没有消费成功，他不管。也就是说，如果发消息的时候，你的客户端挂了，之后再恢复的话，这个消息你就彻底丢失了。（在Redis 5.0之后，因为引入了Stream，是可以用来做延迟消息队列的。）   

### 十、Redis的zset 

虽然基于Redis过期监听的方案并不完美，但是并不是Redis实现关单功能就不完美了，还有其他的方案。  

我们可以借助Redis中的有序集合——zset来实现这个功能。  

zset是一个有序集合，每一个元素(member)都关联了一个 score，可以通过 score 排序来取集合中的值。  

我们将订单超时时间的时间戳（下单时间+超时时长）与订单号分别设置为 score 和 member。这样redis会对zset按照score延时时间进行排序。然后我们再开启redis扫描任务，获取"当前时间 > score"的延时任务，扫描到之后取出订单号，然后查询到订单进行关单操作即可。

**使用redis zset来实现订单关闭的功能的优点是可以借助redis的持久化、高可用机制。避免数据丢失。但是这个方案也有缺点，那就是在高并发场景中，有可能有多个消费者同时获取到同一个订单号，一般采用加分布式锁解决，但是这样做也会降低吞吐型。**  

> 你的问题聚焦于**用 Redis 的 ZSet（有序集合）实现延迟消息**时，在高并发场景下，为什么会出现多个消费者同时获取到同一个订单号，以及采用分布式锁虽然解决了并发安全但会降低吞吐量。
>
> ---
>
> ## 1. ZSet 延迟消息方案简述
>
> - 延迟消息通过 Redis ZSet 存储，score 通常为消息的触发时间戳。
> - 消费者轮询 ZSet，使用 `ZRANGEBYSCORE` 查找 score 小于等于当前时间的消息，然后处理并删除。
>
> ---
>
> ## 2. 为什么会有多个消费者同时获取到同一个订单号？
>
> 这种问题本质上是**并发竞争的数据一致性问题**。原因如下：
>
> ### 并发轮询导致重复获取
>
> - 高并发场景下，多个消费者几乎同时执行 `ZRANGEBYSCORE` 查询。
> - 查询结果可能同时包含某个到期的订单号（如 A、B 两个消费者都查到了订单 X）。
> - 如果后续删除操作（`ZREM`）没有原子性保障，A 和 B 都会尝试处理订单 X。
>
> ### 删除与查询不是原子操作
>
> - 查询（`ZRANGEBYSCORE`）和删除（`ZREM`）是分两步完成的，不是原子性的。
> - A 查询到订单 X，准备处理；B 此刻也查询到订单 X。
> - 如果 A 还没完成 `ZREM`，B 也开始处理，导致重复消费。
>
> ### 高并发放大了时序窗口
>
> - 并发越高，这种“查询到但没来得及删除”的时序窗口越大，重复消费概率越高。
>
> ---
>
> ## 3. 为什么加分布式锁能解决，但会降低吞吐量？
>
> ### 分布式锁解决方式
>
> - 查询到待处理订单后，对订单号加分布式锁（如 Redis 锁、Redisson），只有抢到锁的消费者处理并删除消息。
> - 这样保证了同一订单号同一时刻只会被一个消费者处理。
>
> ### 吞吐量下降原因
>
> - 加锁操作带来额外的网络请求和 Redis 性能消耗，降低了整体处理速度。
> - 锁存在阻塞和竞争，尤其在高并发下，锁的争抢会让大量请求排队，延迟增加，吞吐下降。
>
> ---
>
> ## 总结
>
> > 用 Redis ZSet 实现延迟消息时，查询和删除不是原子操作，导致高并发下多个消费者可能同时获取并处理同一个订单号。加分布式锁虽然能保证同一订单只被处理一次，但会带来额外开销，降低系统吞吐量。
>
> 如需原子性解决方案，可以考虑用 Lua 脚本将查询和删除合并为一个原子操作，或者用支持延迟消息的专业中间件（如 RocketMQ）。

但是，在大多数业务场景下，如果幂等性做得好的，多个消费者取到同一个订单号也无妨。 

> 解答：
>
> ---
>
> 在用 Redis ZSet 或其他类似延迟队列方案时，**多个消费者可能同时取到同一个订单号**，如果业务操作本身具有良好的**幂等性**，其实不会有不良影响，原因如下：
>
> ### 什么是幂等性？
>
> **幂等性**指的是：同一个操作，无论执行多少次，结果都是一致的，不会因为重复执行而造成副作用。比如扣款、发货、状态变更等操作，每次执行的结果都一样。
>
> ---
>
> ### 为什么幂等性可以消除重复消费的风险？
>
> 1. **重复处理不会造成业务异常**  
>    例如，一个订单只能发货一次，如果“发货”接口有幂等性，无论调用多少次，只会发一次货，后续调用会被判定为重复，直接忽略。
>
> 2. **数据一致性保障**  
>    幂等逻辑通常会先判断订单状态、操作标记等，只对未处理的订单进行业务处理，已处理的直接返回。
>
> 3. **系统容错性强**  
>    即使分布式场景下多个消费者同时拿到同一个订单号，都去执行处理逻辑，最终只有一次实际变更，其他操作无副作用。
>
> 4. **简化分布式锁的需求**  
>    如果幂等性做得好，可以减少甚至省掉分布式锁的使用，从而提升系统吞吐量和性能。
>
> ---
>
> ### 典型幂等性实现方式
>
> - 利用唯一约束，比如数据库唯一索引、状态字段。
> - 先查状态再变更，变更操作加幂等校验。
> - 利用去重表、事务、乐观锁等机制。
>
> ---
>
> **总结**：  
> 如果业务操作具备良好的幂等性，即使多个消费者同时处理同一个订单号，也不会导致重复扣款、重复发货等问题，系统最终状态一致。这也是高并发分布式系统设计中的重要原则之一。

### 十一、Redisson + Redis

上面这种方案看上去还不错，但是需要我们自己基于zset这种数据结构编写代码，那么有没有什么更加友好的方式？  

有的，那就是基于Redisson。  

Redisson是一个在Redis的基础上实现的框架，它不仅提供了一系列的分布式的Java常用对象，还提供了许多分布式服务。  

Redisson中定义了分布式延迟队列RDelayedQueue，这是一种基于我们前面介绍过的zset结构实现的延时队列，它允许以指定的延迟时长将元素放到目标队列中。  

**其实就是在zset的基础上增加了一个基于内存的延迟队列**。当我们要添加一个数据到延迟队列的时候，redisson会把数据+超时时间放到zset中，并且起一个延时任务，当任务到期的时候，再去zset中把数据取出来，返回给客户端使用。 

  [Redis如何实现延迟消息](./Redis/Redis如何实现延迟消息？.md)

**基于Redisson的实现方式，是可以解决基于zset方案中的并发重复问题的，而且还能实现方式也比较简单，稳定性、性能都比较高。** 