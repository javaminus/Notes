# 1TB数据只有32GB内存如何排序？

这是典型的“外部排序”问题。因为数据远大于内存，不能一次性全部加载，常用方案是**外部归并排序**（external merge sort）。

---

## 1️⃣ 整体思路

分为两大步骤：

1. **分块排序**（Divide & Sort）  
   - 把1TB数据分成若干个能被内存容纳的小块（每块不超30GB），比如分成36块。
   - 每次将1块读入内存，在内存中用高效算法（快排、归并、Timsort等）排序。
   - 排好后写出到磁盘为临时有序文件（chunk1.sorted, chunk2.sorted ...）。
2. **多路归并**（K-way Merge）  
   - 多个有序块无法全部装入内存，于是设置输入缓冲区和输出缓冲区。
   - 每次从每个有序块读入一部分（如几百MB），用最小堆维护每个块的最小元素。
   - 每次弹出堆顶（最小值）写入输出缓冲区，输出缓冲区满则写入最终结果文件。
   - 如果输入缓冲区耗尽，就从对应块再读一批数据，直到所有块归并完毕。
   - 如果块数较多（如36块），可多轮归并（如每次9块：先合并成4块，再全归并）。

---

## 2️⃣ 具体操作步骤

### A. 分块排序

- 1TB ÷ 30GB ≈ 34块（实际可调整）
- 伪代码：
    ```
    for each chunk in big file:
        load chunk into memory
        sort chunk in memory
        write chunk_sorted_X to disk
    ```

### B. 多路归并

- 假设每次归并9路，分配好输入/输出缓冲区内存。
- 用最小堆维护当前各块的最小值。
- 归并流程：
    1. 打开9个有序文件，为每个文件分配输入缓冲区。
    2. 预读每块部分数据，堆中插入每块的首元素。
    3. 反复弹出堆顶（最小），写到输出缓冲区。
    4. 输出缓冲区满则写入磁盘。
    5. 堆顶元素来自哪个块就补充该块下一个元素进堆。
    6. 某块读空则关闭该块。
    7. 归并结束后，继续多轮归并，直至最终只剩一个有序文件。
- 归并轮数 ≈ logₖ(N)，k为归并路数，N为块数。

---

## 3️⃣ 总结流程图

1. **数据分块 → 内存排序 → 写入临时有序文件**
2. **多路归并（分批/多轮） → 最终有序大文件**

---

## 4️⃣ 实际案例

- Hadoop MapReduce中的Sort、Linux的sort命令、MySQL外部排序，底层本质就是外部归并排序。

---

## 5️⃣ 注意点

- 输入/输出缓冲区要合理分配内存，平衡磁盘IO与内存利用率。
- 可用多线程/并发优化分块和归并阶段。
- 临时文件管理要妥善，归并后及时清理。

---

> 💡 **一句话理解：把1TB数据分成内存能装下的小块分别排序，然后用多轮多路归并方式合成一个大有序文件，这就是大数据排序的经典外部归并排序方案！**