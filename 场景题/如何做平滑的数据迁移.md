# 如何做平滑的数据迁移？

数据迁移指的是将数据从一个数据源迁移到另一个数据源，常见于分库分表、数据库替换、架构变更、历史数据归档等场景。要做好平滑的数据迁移，需要整体设计并关注完整性、实时性和业务无感知。

---

## 1. 迁移前准备

- **明确迁移目的**：分库分表、数据库替换、架构调整、归档等
- **评估数据量**：几十万、几百万、千万、亿级，影响实施方案
- **业务影响评估**：是否可停机迁移，是否需业务无感知

---

## 2. 数据类型

- **存量数据**：原系统已存在的数据
- **增量数据**：迁移过程中新产生的数据（新insert/update/delete）

---

## 3. 关键问题

- **数据完整性**：无丢失、无误迁
- **数据实时性**：新旧数据同步，确保一致
- **数据校验**：迁移后核对一致性
- **灰度控制**：逐步迁移，业务影响最小
- **回滚机制**：可快速回滚至旧系统

---

## 4. 常用工具

- **DataX**：阿里开源离线数据同步工具，支持多种异构数据源
- **Canal**：MySQL增量日志解析工具，支持增量数据订阅与消费
- **Kettle**：开源ETL工具，支持抽取/转换/加载
- **Flink CDC**：实时捕获数据库变更日志，支持流式数据同步

---

## 5. 迁移流程

1. **增量数据核对**
2. **存量数据迁移**
3. **全量数据核对**
4. **双写读旧、写旧**
5. **存量数据核对**
6. **增量数据迁移，双写读新**
7. **数据切流，灰度迁移**
8. **切流核对**

> 迁移过程需实现从“读写旧表”到“读写新表”的平滑过渡。

---

## 6. 双写实现

- **工具增量双写**：如Canal、Flink CDC，基于binlog自动同步新数据至新库
- **代码双写**：在DAO层编码实现，写旧库后写新库，需考虑重试与事务
- **异步双写**：写新库通过MQ异步处理，适合大流量场景

> 双写流程需根据切流阶段调整主写库，保证迁移安全。

---

## 7. 增量数据核对

- **旁路验证**：迁移期间，异步对比新旧库同一条数据，发现不一致及时报警
- **自动/人工核对结合**，确保同步不丢失、不误写

---

## 8. 增量数据更新处理

- 更新/删除时判断数据归属（增量/存量），增量需双写，存量只更新旧库
- 避免增量数据被存量迁移覆盖

---

## 9. 存量数据迁移

- 可用工具或代码分批迁移，确保**断点续传**（失败可恢复）、不丢失数据
- 旧表增加“迁移标记”字段，迁移成功即标记，便于分批处理
- 避免覆盖新表已存在的增量数据

---

## 10. 存量数据核对

- 迁移后逐条核对新旧表数据，确保一致性
- 可用自动化工具/脚本辅助校验

---

## 11. 灰度切流

- 按用户ID尾号等分批切流，从10%到100%，逐步切换读请求到新表
- 切流期间旁路验证切换到旧表，确保数据一致

---

## 12. 切流写新

- 全量切流到新表后，彻底去掉双写，旧表停止写入
- 此步骤不可回滚，务必谨慎，建议先小比例放量

---

## 13. 开关与监控

- 迁移流程关键节点放开关，配置中心可动态调整
- 全链路监控与核对，确保问题可及时发现

---

## 总结

平滑数据迁移需分阶段实现存量和增量数据迁移，双写、核对、灰度切流和监控缺一不可。工具与自研方案结合，根据业务量和复杂度选择最佳实施路径，确保业务无感知和数据安全。